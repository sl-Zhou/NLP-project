{"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5045004,"sourceType":"datasetVersion","datasetId":2928737},{"sourceId":7105186,"sourceType":"datasetVersion","datasetId":4096151}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"accelerator":"GPU"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"olVpflosFGpf","pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","drive.flush_and_unmount()\n","\n","drive.mount('/content/drive')\n","\n","!nvidia-smi"],"metadata":{"id":"vrrx4wDb-MuE","execution":{"iopub.status.busy":"2024-04-08T23:25:47.463857Z","iopub.execute_input":"2024-04-08T23:25:47.464211Z","iopub.status.idle":"2024-04-08T23:25:48.468183Z","shell.execute_reply.started":"2024-04-08T23:25:47.464184Z","shell.execute_reply":"2024-04-08T23:25:48.467044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import necessary libraries\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import classification_report, accuracy_score\n","from tqdm import tqdm\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import numpy as np\n","\n","data = pd.read_csv('/content/drive/MyDrive/project/Jfleg4-2-4.csv')\n","\n","train, test_data = train_test_split(data, test_size=0.2, random_state=42,shuffle=True)\n","train_data, val_data = train_test_split(train, test_size=0.125, random_state=42, shuffle=True)\n","\n","# Data Acquisition\n","class GrammarCorrectionDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_length=128):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        # input_text = self.data.iloc[idx]['source']\n","        # output_text = self.data.iloc[idx]['output']\n","        input_text = self.data.iloc[idx]['input']\n","        output_text = self.data.iloc[idx]['target']\n","\n","\n","        input_encoding = tokenizer.encode_plus(\n","            input_text,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","\n","        target_encoding = tokenizer.encode(\n","            output_text,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'input_ids': input_encoding['input_ids'].squeeze(0),\n","            'attention_mask': input_encoding['attention_mask'].squeeze(0),\n","            'labels': target_encoding.squeeze(0)\n","        }"],"metadata":{"id":"O49kkhXQ05KV","execution":{"iopub.status.busy":"2024-04-08T23:25:51.223117Z","iopub.execute_input":"2024-04-08T23:25:51.223491Z","iopub.status.idle":"2024-04-08T23:26:00.768241Z","shell.execute_reply.started":"2024-04-08T23:25:51.223458Z","shell.execute_reply":"2024-04-08T23:26:00.767193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import GPTNeoXForCausalLM, AutoTokenizer\n","\n","model_pythia = GPTNeoXForCausalLM.from_pretrained(\n","  \"EleutherAI/pythia-70m-deduped\",\n","  revision=\"step3000\",\n","  cache_dir=\"./pythia-70m-deduped/step3000\",\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(\n","  \"EleutherAI/pythia-70m-deduped\",\n","  revision=\"step3000\",\n","  cache_dir=\"./pythia-70m-deduped/step3000\",\n",")\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"8WwSGC7bvrmA","execution":{"iopub.status.busy":"2024-04-08T23:26:07.276892Z","iopub.execute_input":"2024-04-08T23:26:07.277544Z","iopub.status.idle":"2024-04-08T23:26:10.64283Z","shell.execute_reply.started":"2024-04-08T23:26:07.277517Z","shell.execute_reply":"2024-04-08T23:26:10.641868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, data_loader, device):\n","    model.to(device).eval()  # Set the model to evaluation mode\n","\n","    # Confirm the pad_token_id is an integer, if not, set it manually\n","    pad_token_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else -100\n","    # print(f\"Pad token ID: {pad_token_id}\")\n","\n","    total_loss = 0.0\n","    all_preds, all_labels = [], []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","\n","            # Reshape labels to give a flat vector of length batch_size*seq_len\n","            labels = labels.view(-1)\n","            # Same for logits: flatten output predictions\n","            logits = logits.view(-1, model.config.vocab_size)\n","\n","            # Calculate loss using CrossEntropyLoss\n","            loss_fct = torch.nn.CrossEntropyLoss(ignore_index=pad_token_id)\n","            loss = loss_fct(logits, labels)\n","            total_loss += loss.item()\n","\n","            # Convert logits to predicted token indices\n","            preds = torch.argmax(logits, dim=1)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    # Calculate accuracy excluding padding\n","    all_preds = np.array(all_preds)\n","    all_labels = np.array(all_labels)\n","    mask = all_labels != pad_token_id\n","    accuracy = accuracy_score(all_labels[mask], all_preds[mask])\n","\n","    avg_loss = total_loss / len(data_loader)\n","\n","    return avg_loss, accuracy\n"],"metadata":{"id":"ml81gYFNdwVa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the DataLoaders for the train and validation sets\n","batch_size = 8  # You can set the batch size to a suitable value\n","train_dataset = GrammarCorrectionDataset(train_data, tokenizer)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_dataset = GrammarCorrectionDataset(val_data, tokenizer)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Evaluate on the train set\n","train_loss, train_accuracy = evaluate(model_pythia, train_loader, device)\n","print(f\"Training Loss: {train_loss:.4f} | Training Accuracy: {train_accuracy:.4f}\")\n","\n","# Evaluate on the validation set\n","val_loss, val_accuracy = evaluate(model_pythia, val_loader, device)\n","print(f\"Validation Loss: {val_loss:.4f} | Validation Accuracy: {val_accuracy:.4f}\")"],"metadata":{"id":"ObzQs2fDgIXK"},"execution_count":null,"outputs":[]}]}